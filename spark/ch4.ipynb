{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark import SparkConf, SparkContext\n",
    "conf = SparkConf().setMaster(\"local\").setAppName(\"my second app\")\n",
    "sc = SparkContext(conf = conf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdd1.collect() = ['key1 word1', 'key2 word2', '']\n",
      "pairs.collect() = [('key1', 'key1 word1'), ('key2', 'key2 word2'), ('', '')]\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "rdd1 = sc.textFile(\"myTextFile.txt\")\n",
    "print(\"rdd1.collect() =\", rdd1.collect())\n",
    "pairs = rdd1.map(lambda x: (x.split(\" \")[0], x))\n",
    "print(\"pairs.collect() =\", pairs.collect())\n",
    "print(\"123\"[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exampleRdd.collect() = [[1, 2], [3, 4], [3, 6], [3, 7]]\n",
      "examplePairs.collect() = [(1, 2), (3, 4), (3, 6), (3, 7)]\n"
     ]
    }
   ],
   "source": [
    "exampleRdd = sc.parallelize([[1, 2], [3, 4], [3, 6], [3, 7]])\n",
    "print(\"exampleRdd.collect() =\", exampleRdd.collect())\n",
    "examplePairs = exampleRdd.map(lambda x: (x[0], x[1]))\n",
    "print(\"examplePairs.collect() =\", examplePairs.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newRdd.collect() = [(1, 2), (3, 17)]\n"
     ]
    }
   ],
   "source": [
    "newRdd = examplePairs.reduceByKey(lambda x, y: x + y)\n",
    "print(\"newRdd.collect() =\", newRdd.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newRdd2.collect() = [(1, <pyspark.resultiterable.ResultIterable object at 0x01402B70>), (3, <pyspark.resultiterable.ResultIterable object at 0x01402B90>)]\n",
      "groupedRdd.collect() = [(1, [2]), (3, [4, 6, 7])]\n"
     ]
    }
   ],
   "source": [
    "newRdd2 = examplePairs.groupByKey()\n",
    "print(\"newRdd2.collect() =\", newRdd2.collect())\n",
    "groupedRdd = newRdd2.map(lambda x: (x[0], list(x[1])))\n",
    "print(\"groupedRdd.collect() =\", groupedRdd.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newRdd3.collect() = [(1, 3), (3, 5), (3, 7), (3, 8)]\n"
     ]
    }
   ],
   "source": [
    "newRdd3 = examplePairs.mapValues(lambda x: x + 1)\n",
    "print(\"newRdd3.collect() =\", newRdd3.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newRdd4.collect() = [(1, 3), (3, 5), (3, 7), (3, 8)]\n"
     ]
    }
   ],
   "source": [
    "newRdd4 = examplePairs.map(lambda x: (x[0], x[1] + 1))\n",
    "print(\"newRdd4.collect() =\", newRdd4.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "examplePairs.collect(): [(1, 2), (3, 4), (3, 6), (3, 7)]\n",
      "newRdd5.collect() = [1, 3, 3, 5, 3, 7, 3, 8]\n"
     ]
    }
   ],
   "source": [
    "print(\"examplePairs.collect():\", examplePairs.collect())\n",
    "newRdd5 = examplePairs.flatMap(lambda x: (x[0], x[1] + 1))\n",
    "print(\"newRdd5.collect() =\", newRdd5.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "examplePairs.collect(): [(1, 2), (3, 4), (3, 6), (3, 7)]\n",
      "newRdd6.collect() = [1, 3, 3, 3]\n"
     ]
    }
   ],
   "source": [
    "print(\"examplePairs.collect():\", examplePairs.collect())\n",
    "newRdd6 = examplePairs.keys()\n",
    "print(\"newRdd6.collect() =\", newRdd6.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mySet = {1, 3}\n",
      "myList = [1, 3]\n"
     ]
    }
   ],
   "source": [
    "# now I want to suppress duplicates\n",
    "listWithDuplicates = [1, 3, 3, 3]\n",
    "mySet = set(listWithDuplicates)\n",
    "print(\"mySet =\", mySet)\n",
    "myList = list(mySet)\n",
    "print(\"myList =\", myList)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "examplePairs.collect(): [(1, 2), (3, 4), (3, 6), (3, 7)]\n",
      "newRdd7.collect() = [2, 4, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "print(\"examplePairs.collect():\", examplePairs.collect())\n",
    "newRdd7 = examplePairs.values()\n",
    "print(\"newRdd7.collect() =\", newRdd7.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unsortedRdd.collect() = [[1, 1], [3, 3], [2, 2]]\n",
      "unsortedPairsRdd.collect() = [(1, 1), (3, 3), (2, 2)]\n",
      "sortedPairsRdd.collect() = [(1, 1), (2, 2), (3, 3)]\n"
     ]
    }
   ],
   "source": [
    "unsortedKeyValueList = [[1,1], [3,3], [2,2] ]\n",
    "unsortedRdd = sc.parallelize(unsortedKeyValueList)\n",
    "print(\"unsortedRdd.collect() =\", unsortedRdd.collect())\n",
    "unsortedPairsRdd = unsortedRdd.map(lambda x: (x[0], x[1]))\n",
    "print(\"unsortedPairsRdd.collect() =\", unsortedPairsRdd.collect())\n",
    "sortedPairsRdd = unsortedPairsRdd.sortByKey()\n",
    "print(\"sortedPairsRdd.collect() =\", sortedPairsRdd.collect())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subtractedRdd.collect() = [(1, 1), (3, 3)]\n"
     ]
    }
   ],
   "source": [
    "list1 = [[1,1], [3,3], [2,2]]\n",
    "list2 = [[4,4], [2,22]]\n",
    "rdd1 = sc.parallelize(list1)\n",
    "rdd2 = sc.parallelize(list2)\n",
    "pairsRdd1 = rdd1.map(lambda x: (x[0], x[1]))\n",
    "pairsRdd2 = rdd2.map(lambda x: (x[0], x[1]))\n",
    "subtractedRdd = pairsRdd1.subtractByKey(pairsRdd2)\n",
    "print(\"subtractedRdd.collect() =\", subtractedRdd.collect())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joinedRdd.collect() = [(2, (2, 22))]\n"
     ]
    }
   ],
   "source": [
    "joinedRdd = pairsRdd1.join(pairsRdd2)\n",
    "print(\"joinedRdd.collect() =\", joinedRdd.collect())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rightOuterJoinRdd.collect() = [(2, (2, 22)), (4, (None, 4))]\n"
     ]
    }
   ],
   "source": [
    "rightOuterJoinRdd = pairsRdd1.rightOuterJoin(pairsRdd2)\n",
    "print(\"rightOuterJoinRdd.collect() =\", rightOuterJoinRdd.collect())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'PipelinedRDD' object has no attribute 'rightJoin'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m-------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-36727a163bcb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrightJoinRdd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpairsRdd1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrightJoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpairsRdd2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"rightJoinRdd.collect() =\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrightJoinRdd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'PipelinedRDD' object has no attribute 'rightJoin'"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
