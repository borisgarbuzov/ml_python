{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark import SparkConf, SparkContext\n",
    "conf = SparkConf().setMaster(\"local\").setAppName(\"my second app\")\n",
    "sc = SparkContext(conf = conf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdd1.collect() = ['key1 word1', 'key2 word2', '']\n",
      "pairs.collect() = [('key1', 'key1 word1'), ('key2', 'key2 word2'), ('', '')]\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "rdd1 = sc.textFile(\"myTextFile.txt\")\n",
    "print(\"rdd1.collect() =\", rdd1.collect())\n",
    "pairs = rdd1.map(lambda x: (x.split(\" \")[0], x))\n",
    "print(\"pairs.collect() =\", pairs.collect())\n",
    "print(\"123\"[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exampleRdd.collect() = [[1, 2], [3, 4], [3, 6], [3, 7]]\n",
      "examplePairs.collect() = [(1, 2), (3, 4), (3, 6), (3, 7)]\n"
     ]
    }
   ],
   "source": [
    "exampleRdd = sc.parallelize([[1, 2], [3, 4], [3, 6], [3, 7]])\n",
    "print(\"exampleRdd.collect() =\", exampleRdd.collect())\n",
    "examplePairs = exampleRdd.map(lambda x: (x[0], x[1]))\n",
    "print(\"examplePairs.collect() =\", examplePairs.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newRdd.collect() = [(1, 2), (3, 17)]\n"
     ]
    }
   ],
   "source": [
    "newRdd = examplePairs.reduceByKey(lambda x, y: x + y)\n",
    "print(\"newRdd.collect() =\", newRdd.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newRdd2.collect() = [(1, <pyspark.resultiterable.ResultIterable object at 0x0A4CC5D0>), (3, <pyspark.resultiterable.ResultIterable object at 0x0A4CC5F0>)]\n",
      "groupedRdd.collect() = [(1, [2]), (3, [4, 6, 7])]\n"
     ]
    }
   ],
   "source": [
    "newRdd2 = examplePairs.groupByKey()\n",
    "print(\"newRdd2.collect() =\", newRdd2.collect())\n",
    "groupedRdd = newRdd2.map(lambda x: (x[0], list(x[1])))\n",
    "print(\"groupedRdd.collect() =\", groupedRdd.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newRdd3.collect() = [(1, 3), (3, 5), (3, 7), (3, 8)]\n"
     ]
    }
   ],
   "source": [
    "newRdd3 = examplePairs.mapValues(lambda x: x + 1)\n",
    "print(\"newRdd3.collect() =\", newRdd3.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newRdd4.collect() = [(1, 3), (3, 5), (3, 7), (3, 8)]\n"
     ]
    }
   ],
   "source": [
    "newRdd4 = examplePairs.map(lambda x: (x[0], x[1] + 1))\n",
    "print(\"newRdd4.collect() =\", newRdd4.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "examplePairs.collect(): [(1, 2), (3, 4), (3, 6), (3, 7)]\n",
      "newRdd5.collect() = [1, 3, 3, 5, 3, 7, 3, 8]\n"
     ]
    }
   ],
   "source": [
    "print(\"examplePairs.collect():\", examplePairs.collect())\n",
    "newRdd5 = examplePairs.flatMap(lambda x: (x[0], x[1] + 1))\n",
    "print(\"newRdd5.collect() =\", newRdd5.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "examplePairs.collect(): [(1, 2), (3, 4), (3, 6), (3, 7)]\n",
      "newRdd6.collect() = [1, 3, 3, 3]\n"
     ]
    }
   ],
   "source": [
    "print(\"examplePairs.collect():\", examplePairs.collect())\n",
    "newRdd6 = examplePairs.keys()\n",
    "print(\"newRdd6.collect() =\", newRdd6.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mySet = {1, 3}\n",
      "myList = [1, 3]\n"
     ]
    }
   ],
   "source": [
    "# now I want to suppress duplicates\n",
    "listWithDuplicates = [1, 3, 3, 3]\n",
    "mySet = set(listWithDuplicates)\n",
    "print(\"mySet =\", mySet)\n",
    "myList = list(mySet)\n",
    "print(\"myList =\", myList)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "examplePairs.collect(): [(1, 2), (3, 4), (3, 6), (3, 7)]\n",
      "newRdd7.collect() = [2, 4, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "print(\"examplePairs.collect():\", examplePairs.collect())\n",
    "newRdd7 = examplePairs.values()\n",
    "print(\"newRdd7.collect() =\", newRdd7.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unsortedRdd.collect() = [[1, 1], [3, 3], [2, 2]]\n",
      "unsortedPairsRdd.collect() = [(1, 1), (3, 3), (2, 2)]\n",
      "sortedPairsRdd.collect() = [(1, 1), (2, 2), (3, 3)]\n"
     ]
    }
   ],
   "source": [
    "unsortedKeyValueList = [[1,1], [3,3], [2,2] ]\n",
    "unsortedRdd = sc.parallelize(unsortedKeyValueList)\n",
    "print(\"unsortedRdd.collect() =\", unsortedRdd.collect())\n",
    "unsortedPairsRdd = unsortedRdd.map(lambda x: (x[0], x[1]))\n",
    "print(\"unsortedPairsRdd.collect() =\", unsortedPairsRdd.collect())\n",
    "sortedPairsRdd = unsortedPairsRdd.sortByKey()\n",
    "print(\"sortedPairsRdd.collect() =\", sortedPairsRdd.collect())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subtractedRdd.collect() = [(1, 1), (3, 3)]\n"
     ]
    }
   ],
   "source": [
    "list1 = [[1,1], [3,3], [2,2]]\n",
    "list2 = [[4,4], [2,22]]\n",
    "rdd1 = sc.parallelize(list1)\n",
    "rdd2 = sc.parallelize(list2)\n",
    "pairsRdd1 = rdd1.map(lambda x: (x[0], x[1]))\n",
    "pairsRdd2 = rdd2.map(lambda x: (x[0], x[1]))\n",
    "subtractedRdd = pairsRdd1.subtractByKey(pairsRdd2)\n",
    "print(\"subtractedRdd.collect() =\", subtractedRdd.collect())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joinedRdd.collect() = [(2, (2, 22))]\n"
     ]
    }
   ],
   "source": [
    "joinedRdd = pairsRdd1.join(pairsRdd2)\n",
    "print(\"joinedRdd.collect() =\", joinedRdd.collect())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rightOuterJoinRdd.collect() = [(2, (2, 22)), (4, (None, 4))]\n",
      "leftOuterJoinRdd.collect() = [(2, (2, 22)), (1, (1, None)), (3, (3, None))]\n"
     ]
    }
   ],
   "source": [
    "rightOuterJoinRdd = pairsRdd1.rightOuterJoin(pairsRdd2)\n",
    "print(\"rightOuterJoinRdd.collect() =\", rightOuterJoinRdd.collect())\n",
    "leftOuterJoinRdd = pairsRdd1.leftOuterJoin(pairsRdd2)\n",
    "print(\"leftOuterJoinRdd.collect() =\", leftOuterJoinRdd.collect())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pairsRdd1.collect() = [(1, 1), (3, 3), (2, 2)]\n",
      "pairsRdd2.collect() = [(4, 4), (2, 22)]\n",
      "cogroupRdd.collect() = [(2, (<pyspark.resultiterable.ResultIterable object at 0x0A4D40B0>, <pyspark.resultiterable.ResultIterable object at 0x0A4D4E70>)), (4, (<pyspark.resultiterable.ResultIterable object at 0x0A4D4B50>, <pyspark.resultiterable.ResultIterable object at 0x0A4D4D10>)), (1, (<pyspark.resultiterable.ResultIterable object at 0x0A4D4E50>, <pyspark.resultiterable.ResultIterable object at 0x0A4D4C70>)), (3, (<pyspark.resultiterable.ResultIterable object at 0x0A4D4290>, <pyspark.resultiterable.ResultIterable object at 0x0A4D4D30>))]\n",
      "[(2, ([2], [22])), (4, ([], [4])), (1, ([1], [])), (3, ([3], []))]\n"
     ]
    }
   ],
   "source": [
    "print(\"pairsRdd1.collect() =\", pairsRdd1.collect())\n",
    "print(\"pairsRdd2.collect() =\", pairsRdd2.collect())\n",
    "cogroupRdd = pairsRdd1.cogroup(pairsRdd2)\n",
    "print(\"cogroupRdd.collect() =\", cogroupRdd.collect())\n",
    "\n",
    "complicated_construction = [(x, tuple(map(list, y))) for x, y in list(cogroupRdd.collect())]\n",
    "print(complicated_construction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pair =  (1, [[11, 12], [13, 14]])\n",
      "key =  1 , value = [[11, 12], [13, 14]]\n",
      "pair =  (2, [[22, 23], [24, 25]])\n",
      "key =  2 , value = [[22, 23], [24, 25]]\n",
      "pair =  (3, [[33, 34], [35, 36]])\n",
      "key =  3 , value = [[33, 34], [35, 36]]\n",
      "newList = [(1, [[11, 12], [13, 14]]), (2, [[22, 23], [24, 25]]), (3, [[33, 34], [35, 36]])]\n",
      "simpleList = [1, 2, 3]\n",
      "simpleTuple = (1, 2, 3)\n",
      "listAgain = [1, 2, 3]\n",
      "coordinate1 = 1 coordinate2 = 2 coordinate3 = 3\n",
      "type(simpleSimpleTuple) = <class 'tuple'>\n",
      "simpleSimpleTuple = (1, 2, 3)\n",
      "myMapList = <map object at 0x0A4D4510>\n",
      "listPlus1 = [2, 3, 4]\n",
      "listSum = [123, 246]\n",
      "myGeneratorList = [1, 4]\n"
     ]
    }
   ],
   "source": [
    "# [(x, tuple(map(list, y))) for x, y in list(cogroupRdd.collect())]\n",
    "myPairList = [(1, [[11, 12], [13, 14]]), (2, [[22, 23], [24, 25]]), (3, [[33, 34], [35, 36]])]\n",
    "newList = []\n",
    "for pair in myPairList:\n",
    "    print (\"pair = \", pair)\n",
    "    key, value = pair[0], pair[1]\n",
    "    print (\"key = \", key, \", value =\", value)\n",
    "    newList.append((key, value))\n",
    "print(\"newList =\", newList)\n",
    "simpleList = [1, 2, 3]\n",
    "print(\"simpleList =\", simpleList)\n",
    "simpleTuple = tuple(simpleList)\n",
    "print(\"simpleTuple =\", simpleTuple)\n",
    "listAgain = list(simpleTuple)\n",
    "print(\"listAgain =\", listAgain)\n",
    "(coordinate1, coordinate2, coordinate3) = simpleTuple\n",
    "print(\"coordinate1 =\", coordinate1, \"coordinate2 =\", coordinate2, \"coordinate3 =\", coordinate3)\n",
    "simpleSimpleTuple = (1, 2, 3)\n",
    "print(\"type(simpleSimpleTuple) =\", type(simpleSimpleTuple))\n",
    "\n",
    "print(\"simpleSimpleTuple =\", simpleSimpleTuple)\n",
    "# map function\n",
    "# instead of list function use map, to make a list out of tuple\n",
    "myMapList = map(list, simpleSimpleTuple)\n",
    "print(\"myMapList =\", myMapList)\n",
    "# the above needs adjustment\n",
    "simpleList = [1, 2, 3]\n",
    "listPlus1 = list(map(lambda x: x+1, simpleList))\n",
    "print(\"listPlus1 =\", listPlus1)\n",
    "# may be in a new implementation they changed it, and they return the object map\n",
    "onePlusTwo = list(map(lambda x, y, z: x+y+z, [1, 2, 3], [11, 22], [111, 222, 333, 444]))\n",
    "print(\"listSum =\", onePlusTwo)\n",
    "myGeneratorList = [x**2 for x in [1, 2]]\n",
    "print(\"myGeneratorList =\", myGeneratorList)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result.collect() = [(2, '123456789012345678901')]\n"
     ]
    }
   ],
   "source": [
    "numStringPairsList = [[1,\"1\"], [3,\"3\"], [2,\"123456789012345678901\"]]\n",
    "numStringRdd = sc.parallelize(numStringPairsList)\n",
    "numStringPairsRdd = numStringRdd.map(lambda x: (x[0], x[1]))\n",
    "result = numStringPairsRdd.filter(lambda keyValue: len(keyValue[1]) > 20)\n",
    "print(\"result.collect() =\", result.collect())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyValue1Rdd.collect() = [('panda', (0, 1)), ('pink', (3, 1)), ('pirate', (3, 1)), ('panda', (1, 1)), ('pink', (4, 1))]\n",
      "reducedRdd.collect() = [('panda', (1, 2)), ('pink', (7, 2)), ('pirate', (3, 1))]\n",
      "averagedRdd.collect() = [('panda', 0.5), ('pink', 3.5), ('pirate', 3.0)]\n"
     ]
    }
   ],
   "source": [
    "stringNumPairsList = [[\"panda\", 0], [\"pink\", 3], [\"pirate\", 3], [\"panda\", 1], [\"pink\", 4]]\n",
    "stringNumRdd = sc.parallelize(stringNumPairsList)\n",
    "stringNumPairsRdd = stringNumRdd.map(lambda x: (x[0], x[1]))\n",
    "keyValue1Rdd = stringNumPairsRdd.mapValues(lambda x: (x, 1))\n",
    "print(\"keyValue1Rdd.collect() =\", keyValue1Rdd.collect())\n",
    "reducedRdd = keyValue1Rdd.reduceByKey(lambda x, y: (x[0] + y[0], x[1] + y[1]))\n",
    "print(\"reducedRdd.collect() =\", reducedRdd.collect())\n",
    "averagedRdd = reducedRdd.mapValues(lambda x: (x[0] / x[1]))\n",
    "print(\"averagedRdd.collect() =\", averagedRdd.collect())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sumCount.collect() = (6, 3)\n",
      "newVar = 2.0\n"
     ]
    }
   ],
   "source": [
    "numList = [1, 2, 3]\n",
    "numRdd = sc.parallelize(numList)\n",
    "sumCount = numRdd.aggregate((0, 0),\n",
    "                            (lambda acc, value: (acc[0] + value, acc[1] + 1)),\n",
    "                             (lambda acc1, acc2: (acc1[0] + acc2[0], acc1[1] + acc2[1])))\n",
    "print(\"sumCount.collect() =\", sumCount)\n",
    "newVar = sumCount[0] / float(sumCount[1])\n",
    "print(\"newVar =\", newVar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sumCount.collect() = 6\n"
     ]
    }
   ],
   "source": [
    "# more elementary with aggregate\n",
    "numList = [1, 2, 3]\n",
    "numRdd = sc.parallelize(numList)\n",
    "sumCount = numRdd.aggregate(0,\n",
    "                            (lambda acc, value: acc + value),\n",
    "                             (lambda acc1, acc2: acc1 + acc2))\n",
    "print(\"sumCount =\", sumCount)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sumCount = 2\n"
     ]
    }
   ],
   "source": [
    "# fold\n",
    "numList = [1, 2, 3, 4]\n",
    "numList = []\n",
    "numRdd = sc.parallelize(numList)\n",
    "sumCount = numRdd.fold(1, lambda acc1, acc2: acc1 + acc2)\n",
    "print(\"sumCount =\", sumCount)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numRdd.collect() = [1, 2, 3, 4, 5]\n",
      "sumCount = 165\n"
     ]
    }
   ],
   "source": [
    "# fold 2\n",
    "numList = [1, 2, 3, 4, 5]\n",
    "numRdd = sc.parallelize(numList, 2)\n",
    "print(\"numRdd.collect() =\", numRdd.collect() )\n",
    "sumCount = numRdd.fold(50, lambda acc1, acc2: acc1 + acc2)\n",
    "print(\"sumCount =\", sumCount)\n",
    "# should be plus 4. B, Va. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "<lambda>() missing 1 required positional argument: 'z'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m-------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-46fad4c2a888>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mnumList\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mnumRdd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparallelize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumList\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0msumCount\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumRdd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"sumCount =\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msumCount\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# B = 3, Va = 6, M = fail .\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\spark\\python\\pyspark\\rdd.py\u001b[0m in \u001b[0;36mfold\u001b[1;34m(self, zeroValue, op)\u001b[0m\n\u001b[0;32m    916\u001b[0m         \u001b[1;31m# to the final reduce call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m         \u001b[0mvals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 918\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzeroValue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    920\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0maggregate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzeroValue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseqOp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcombOp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\spark\\python\\pyspark\\util.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     97\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m             raise RuntimeError(\n",
      "\u001b[1;31mTypeError\u001b[0m: <lambda>() missing 1 required positional argument: 'z'"
     ]
    }
   ],
   "source": [
    "# fold two pluses\n",
    "numList = []\n",
    "numRdd = sc.parallelize(numList)\n",
    "#sumCount = numRdd.fold(1, lambda x, y, z: x + y + z)\n",
    "#print(\"sumCount =\", sumCount)\n",
    "# B = 3, Va = 6, M = fail . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
